{"podcast_details": {"podcast_title": "The Best of Making Sense with Sam Harris", "episode_title": "#96 \u2014 The Nature of Consciousness", "episode_image": "https://ssl-static.libsyn.com/p/assets/0/7/c/3/07c3f49f8b5feae85f2e77a3093c12a1/TBOMS_Chrome_Final.jpg", "episode_transcript": " Welcome to the Making Sense Podcast. This is Sam Harris. Just a note to say that if you're hearing this, you are not currently on our subscriber feed and will only be hearing the first part of this conversation. In order to access full episodes of the Making Sense Podcast, you'll need to subscribe at SamHarris.org. There you'll find our private RSS feed to add to your favorite podcatcher, along with other subscriber-only content. We don't run ads on the podcast, and therefore it's made possible entirely through the support of our subscribers. So if you enjoy what we're doing here, please consider becoming one. Welcome to the best of making sense. This is Sam Harris. In this series, we re-air some of the most popular episodes of the Making Sense Podcast. These are conversations that we think you'll find just as relevant today as when they were originally released. Today I am speaking with the philosopher Thomas Metzinger. Thomas is a full professor and director of the Theoretical Philosophy Group and the Research Group on Neuroethics and Neurophilosophy at Johannes Gutenberg University in Germany. He is the founder and director of the MIND Group and adjunct fellow at the Frankfurt Institute of Advanced Studies, also in Germany. His research centers on the analytic philosophy of mind and applied ethics and the philosophy of cognitive science. And he is the editor and author of several books. He edited the Neurochoroliths of Consciousness, and he wrote Being No One and The Ego Tunnel. In addition to being a philosopher of mind, Thomas is also a long-term meditator. So as you can hear, we have many, many interests in common. We talk about the role of intuition in science, the ethics of building conscious AI, the self as a hallucination, how we identify with our thoughts and the paradox of doing that, attention as the root of the felt sense of self, and the place of Eastern philosophy in Western science, as well as the limitations of secular humanism. So it's a very rich conversation, and it is a conversation that many of you asked for. Many of you have requested that I get Thomas on the podcast. So I bring you Thomas Metzinger. I am here with Thomas Metzinger. Thomas, thanks for coming on the podcast. Good to meet you. Yeah, we've never met, but I have followed you for some time now. I've been a happy reader of your books and the anthologies you've edited. You've done really great work in the philosophy of mind, and this has been an area that I've been interested in for some time. We might have been at the same conference at some point and just didn't get a chance to meet, but it's a pleasure to meet you virtually. I've had to live with emails by people telling me, Thomas, Sam Harris, this guy is like you. I like your website. I wouldn't wish that on anyone. So Thomas, tell our listeners what your focus has been in philosophy in general and what work you're doing now. And then we're going to get into obviously questions of consciousness and AI and the self and all your areas of interest. But how do you summarize what you do as a philosopher at this point? Well, my core competence is in something that's called analytical philosophy of mind. That's where I come from. I've done that for about three decades. But one thing that is special about me is that I have done it in very strong cooperation with neuroscientists, cognitive scientists, AI people for about 30 years. So my job has been to open up analytical philosophy of mind for a deeper and more productive interdisciplinary cooperation. I've got a lot of resistance for this in my life. It was bad for my academic career. But now five years younger, there were four people in Germany like myself. And now it's just like a people's movement. All of the good young philosophers have one empirical area like dreaming, social cognition, predictive coding, where they're really good and they combine this. But in this country, I got all the resistance. What form did the resistance take and what specifically was it focused on? Oh, many different types. First, in Germany, philosophy has very strongly meant history of philosophy. Secondly, something like naturalism has always had a bad press. People who thought, at least I have learned this as a student, that empirical scientists could contribute anything like bottom-up constraints for conceptual work just hadn't understood what philosophy was in the first place because it was purely a priori theorizing. But then there's also this territorial thing. I think you have recently had, for instance, to take this example of a freedom of the will debate too. We had a very hot one a little earlier in the public. And a typical event was that prominent neuroscientists said there is no such thing as freedom of the will. And it got to a point where philosophers said, listen, this is not to be decided in the hard sciences at all. This is a philosophical problem and there will be a philosophical solution. And then my friends from the neuroscience said, you're beginning to understand it. It's not your problem anymore. We have solved it. And then all of the humanities just rose in protest. So it's also a question who is allowed to answer which questions. So you introduced yourself as an analytic philosopher that is usually contrasted with continental philosophy. Has the European commitment to what is known perhaps mostly in the States as continental philosophy, is that part of the problem here? It's part of the problem. Now there is pretty much of a peaceful coexistence. It has gone through many stages, but you must also see the historical situation. In World War II, we have either murdered or driven out of the country all of the Jewish intelligentsia. So many teacher-disciple relationships were completely cut off. And I'm very grateful to the generation of analytical philosophers who came before me to reconnect us to the global discussion again, to mankind's philosophical conversation. That was something that had to be established first after World War II because there were many people who thought the hottest and most recent stuff is Heidegger. Who had more than a superficial connection with the trends that got so many people murdered and exiled. Of course. Yeah. So that's a fascinating moment of intellectual history. And this is not something I'm sure someone has written about it in Germany, but in English I haven't read much about the way in which the war affected philosophy. But it's interesting to picture those teacher-student relationships being severed and Germany becoming isolated as a result. So Thomas, let's start with consciousness. We have questions of intellectual and moral interests that will outlive us. And they outlived Plato, they outlived the Buddha, they outlived everyone who has touched them and I think they will endure. But the mystery of consciousness, how do you think about consciousness? Well, I've been in this for 30 years now. You may know that I'm one of the people who founded the Association for the Scientific Study of Consciousness 22 years ago. I think the first thing we have to understand that consciousness is not one problem, but that it's a whole bundle of problems, some more conceptual, some more empirical. And that's the first step. It's not that one big mystery out there. There's a tension, a sensory discrimination, there are conceptual issues about what may be conceivable and so forth. And I think the consciousness community in the last two decades has really made breathtaking progress. We're getting somewhere. And in this one popular book, The Egotonal, I've actually predicted that by 2050, we will have the global neural correlate of consciousness. We will isolate that in humans. And that's only a very first step. But I think it will not be a mystery. Life is not a mystery anymore. But 150 years ago, many people thought that this is an irreducible mystery. So you're not a fan anymore, if you ever were, of the framing by David Chalmers of the hard problem of consciousness? No, that's so boring. I mean, that's last century. You know, we all respect Dave. We know he's very smart and has got a very fast mind. There's no debate about that. But conceivability arguments are just very, very weak. If you have an ill-defined folk psychological umbrella term like consciousness, then you can pull off all kinds of scenarios and zombie thought experiments. It doesn't really help to clarify some issues in the mid 90s. But the consciousness community has listened to this and just moved on. I mean, nobody of the serious researchers in the field thinks about this anymore. But it has taken on like a folkloristic life of its own. There's a lot of people talk about the hard problem, who wouldn't be able to state what it consists in. Well, maybe we should just state it just so that those listeners who didn't hear me speak with David on the podcast or haven't read my book Waking Up. Basically, the issue is this, that consciousness, if you define it as, to follow Thomas Nagel here, the fact that it's like something to be what you are, the fact that a brain of sufficient complexity or a creature at a certain point in evolutionary terms has a subjective, qualitative perspective on the world. The lights go on. This formulation, I mean, there've been many variants of it, but famously, the philosopher Thomas Nagel wrote a paper, a very influential paper in the early 70s titled, What is it like to be a bat? And he said, you know, we may never know, a bat experience could be totally unlike our own. But if it is like something to be a bat, if you switch places with a bat, that wouldn't be synonymous with just the canceling of experience, but you would be laid bare to a different domain of experience. Well, that is the fact of consciousness in the case of a bat. Whether we ever understand it or not, the fact that the lights are on, the fact that there is a perspectival qualitative character there, that is what we mean by consciousness. And I've always thought that that is a good definition. It doesn't answer any of what Chalmers called the easy problems of consciousness. Those are separate, you know, how does the eye and the visual cortex transduce light energy into a visual mapping of the visual scene? The hard problem on Chalmers' account is always this bit, the fact that it's like something to do any of that, because it's the transition from unconscious seeing, which human brains do and robots do, to the conscious experience of seeing, which we know humans accomplish, and at the moment there's no good reason to think our robots or computers do. A corollary to this framing is that any explanation we get about consciousness, let's just say we open the back of the book of nature and we get the right answer about consciousness, and it turns out that you need exactly 10,000 information processing units of a certain character. They have to be wired in a certain way. They have to be firing at a certain hertz. And just lo and behold, that is what gives you consciousness. And if you change any of those parameters, well, then the lights go out. Let's say we knew that to be true. It still wouldn't explain the emergence of consciousness in a way that is intuitively graspable. It still would seem like a miracle. And that's not the way most or really any satisfying scientific explanation works out. When I give you an explanation for any higher level property, the fluidity of water or the brittleness of glass in terms of its micro constituents, well, then that explanation actually does run through and conserves your intuitions about how things function at a lower level so as to appear as they do on a higher level. And so it is, I would argue, even with the example you just gave of life. So you said that 100 years ago, or even less, 70 years ago, perhaps, let me get my dates right, it's more like 80 years ago, people felt that we would never have a satisfactory explanation of what life is or how life, the energy of life relates to physical structure and how heredity could be a mere mechanism and how the healing of disease or from wounds could be just a matter of chemistry. But of course, with the advent of molecular biology and other insights, we figured all of that out without really without remainder and therefore vitalism or a notion that there has to be any kind of life spirit in matter that has gone out the window. That's another analogy that doesn't really get at how mysterious consciousness is because something like reproduction or growth or healing from injury, that really can be explained mechanistically and our intuitions run through there. So the conceivability issue for me with the hard problem isn't so much a statement about what is true. It's not that I doubt that consciousness can be an emergent property of information processing because it's so difficult to conceive or impossible to conceive how that works. But it is just a statement about the seeming limits of explanation. It sounds to me that whatever you put in the space provided will still sound like the restatement of a miracle, which is really analogous to how to take an analogy to cosmology, the idea that everything, including the laws of nature, emerged out of nothing, right? Like just things exploded into being. Now that may in fact be true, but I would argue, or at least it seems to me, that it's inconceivable or uninterpretable or it's not understandable. It's the statement of a miracle. And so that's really my fondness for the hard problem is a matter of epistemology more than it is ontology. Dr. Klaus Schwab Beautiful. Beautiful. You've now mentioned so many important points that I don't really know where to start. Maybe we should just say technically the hard problem is that phenomenal properties only nomologically supervene on functional properties, but not logically. That is, the conscious properties of sweetness or redness or whatever the bat perceives is determined by information flow in its brain in this world under the laws of nature holding in this world. But there are other worlds where we can imagine that the bat is a zombie, or with exactly that information flow in its brain, that there could always be a functional isomorph to some entity that has the same functions on a certain level of granularity, but which instantiates no phenomenal properties. Dr. Justin Marchegiani Thomas, I just want to jump in here for one second because I want people to understand the distinctions you're making and you used some terms that will lose most people who are not philosophically trained. So I think you hit upon that consciousness nomologically supervenes upon the physical or something like that. You should unpack that and also nomologically means under the laws of nature holding in our universe. Now, there could be other universes, logically possible worlds in which these laws of nature do not hold. So the idea is that consciousness is determined from below from the brain may only hold in this world with these laws of nature, but it's not conceptually something that may hold across all possible worlds. That's the idea that that is the mystery that you are trying to isolate, that the mystery consists in the fact that we can always imagine that Sam Harris is a zombie, that he would talk, he would even talk about his emotions and his color experiences, but he would not have any insight in inner perspective. That's the idea. That's the mystery. Dr. Justin Marchegiani Well, I would strike a slightly different emphasis here, Thomas, just to catch people up. There's this argument that is a I don't know if it originates with Chalmers and he certainly made good use of it in his book, but this idea that we can conceive of a zombie, which is a being that functions and appears exactly like a human being, but has no conscious experience. The lights are not on in a zombie. It's just a perfectly humanoid robot that has no subjectivity or qualitative experience. Now, the fact that we can imagine such a thing does not even slightly suggest that such a thing is possible. It just may be that in order to get something that functions like a human being and seems like a human being from the outside, consciousness is always going to be necessary or will always come along for the ride. And I'm just agnostic as to whether or not that's the case. And you know, I think as we develop AI, we may learn more and more about whether or not that's the case or cease to find it intellectually interesting. So I'm not arguing from the side of it's conceivable that there could be a zombie Sam and therefore there's a hard problem of consciousness. It's more that whatever I imagine the explanation to be, the idea that, you know, the first the lights are not on and then they come on by virtue of some complexity in the system, some... Oh, complexity doesn't explain anything. Complexity is not good. But then you can keep changing the noun, whether it's information integration or... Sure, sure, sure. So whatever the answer is, and there have been various answers proffered in recent decades, it still sounds like just a brute fact that doesn't actually explain anything. And that again, it's not the way other scientific explanations even with respect to life function. Well, the last point may not be right. But what you're actually getting at is what is the value of intuitions? Can we demand of a good theory of consciousness that it gives us an intuitive feeling this is right? Now I've understood it. We would never ask this of a theoretical physicist. If they tell us something about 11 dimensions and string theory, nobody would say, this is completely counterintuitive. This has nothing to do with my life world. This is just brute facts they're stipulating. We just trust these people. They know math. They have theories with high predictive power. They're very smart. And we don't demand this intuition. I would say we actually do. This has been famously what has been so unsatisfying about quantum mechanics, which is that no one, not even Richard Feynman can pretend to understand it. All the physicists can say is that the math works out and it has immense predictive value. But it's still... That is enough. It could be enough. It could be enough. And I take your point about the limit of intuition in that our intuitions were not designed by evolution for us to grasp reality as it is. Our intuitions were designed to avoid getting hit over the head by another ape or to make a mate with his sister. Our intuitions are very crude. But again, we use certain intuitions that we have, whether mathematical or otherwise, to leverage ourselves into areas where our intuitions, our common sense intuitions, and certainly our folk psychological intuitions, are not good. So I can certainly follow you there. But it still just seems to be the case that consciousness provides some kind of extra impediments here. So take something like platform independence. So if we assume that there's nothing magical about having a computer made of meat and consciousness is as mind is, as intelligence is, clearly platform independent, and therefore we could in principle build conscious computers that were non-biological, how would we move, in your view, from having characterized the neural correlate of consciousness in people into being confident that the computers that seem to emulate that functionally and informationally are themselves conscious? What I'm imagining the future of AI will very likely look like is that we will build computers that pass the Turing test with flying colors. Whether or not we figured out the neural correlate of consciousness in apes like ourselves, we will build computers that pass the Turing test and that seem conscious to us. But unless we fully understand how consciousness emerges, we won't know whether they're conscious. They might say they're conscious. They might seem even more conscious than we are. And we will sort of lose sight of the problem. And I know you think that, as I do, that the fact of the matter, whether or not they are conscious is hugely important, ethically speaking. And it would be monstrous to create computers that could suffer. So let's perhaps bring the platform independence issue into this conversation. And I know I've been talking a lot. I just want to kind of give you the full landscape of my prejudice and confusion so that you can run over it. No, no, no. It's all very interesting. And of course, I fully understand what you mean. But we have to think about intuitions a little bit. They have a long evolutionary history. If I have an intuition that an explanation is satisfactory, it is itself a kind of conscious experience. I don't know if you've ever thought about this. There's not only a phenomenology of redness. There's also a phenomenology of I just know this, but I don't know for what reason I know it or where the knowledge comes from. And in many cases, intuitive knowledge is fantastic. It condenses knowledge from the world of our ancestors. Just think about social cognition. If you have to set this intuition, this guy is dangerous or she is a good person. This is a way of computing itself. It doesn't generate sentences in your head but intuitions. Now, the question is, could we ever be intuitively satisfied? I think we cannot because our theory of consciousness will also tell us what a self is and what a first person perspective is. And that is something we will not be able to ever grasp intuitively what's coming out of there. But to come back to your question, you know that for a number of years, I've strictly argued against even risking phenomenal states in machines. We should in no way try attempt to create conscious machines or even get close because we might cause a cascade of suffering. We might just increase the overall amount of suffering in the universe. And just because of this reason, it's very important to have a theory of consciousness. We must have one. So what would we do if we have the global neural correlate of consciousness? That was your question. The hardware doesn't matter. We need to know the flow of information. What is the computation that is carried out? Then we have to describe this on the right level of conceptual granularity, meaning what corresponds to my experience of readiness? What in that information flow is minimally sufficient for my intuition that we will never understand consciousness? What is minimally sufficient for my sense of selfhood and so forth? And if we have that mapping from our own phenomenology to fine-grained computational descriptions, then we can see is this instantiated in a machine or not. The problem, rather, is that machines could have forms of suffering or forms of selfhood that we cannot even grasp because they are so alien and so different from our biological form of conscious experience or emotion. Maybe they would develop it and we wouldn't see it. Maybe it is already there and we wouldn't discover it. So there's certainly a great problem across spaces, spaces of conscious experience, just as with the bat, you're never going to understand what does it feel like to be the bat. I mean to hear the echo of your own ultrasonic calls. Is it like hearing? I've heard people say, no, it's the dominant modality for the bat. It's for the bat. It's like seeing. Other people say, no, it's scanning a surface. It must be a tactile experience for the bat. It's like feeling a surface to fly through that echo. And that is, if it has data formats, as I call it, internal data formats that we don't have in sensory processing, that is something we will never know how it feels to instantiate these data formats. And that may be happening with your machines as well, right? Just on this point of echolocation, I don't know if this is analogous to what a bat experiences, but contrary to what most people assume, we can echolocate to some degree. If you just hold your hand in front of your face and hum and then move your hand back and forth, you will notice that your humming reveals to you the location of your hand. So you can be a very bad bat if you want to try this at home. So let's talk about the self. You raised the topic of the self, which is another thing that people find inscrutable. And it, of course, relates to consciousness. And yet it is quite different. And I want to, you know, you have written a lot about the self and I haven't read everything you've written, but I feel like there is some significant agreement here between the way we view it and the way even traditional views that one meets in the East, like in Buddhism or Advaita Vedanta, that the self as most people conceive of it is an illusion. So I just want to, I put that to you. I think we want to distinguish between the whole person and, you know, I would not say that people are illusions, but most people are walking around with a sense that they have a self inside their heads, that there's a subject in the head, a thinker of thoughts, an experiencer of experience. This is kind of an unchanging rider on the horse of consciousness that just gets carried through from one moment to another and has various adventures, but is in some sense never quite changed by them. It's the center of the whole drama. How do you think about the self and in what sense are people confused about it? Well, when I looked at the problem of consciousness, I thought if I was an anti-reductionist, the most interesting, the most pressing problem is what is a first person perspective and what would it mean for any information processing system to have a sense of selfhood and a first person perspective originating from it. This is the really difficult problem to solve, I think. And I have, just as you, been guilty of this illusion talk in popular writings in the past. Of course, it is conceptual nonsense to say the self is an illusion because as a term, illusion means that there is a sensory misrepresentation of something where an outside stimulus action actually exists. A hallucination is something where there's no stimulus and you still have a misrepresentation. But the sense of selfhood is only partly a sensory experience. Of course, it is grounded in what I call the introspective self model in inner sensations in the body, in effective tone, in the emotions, in elementary bioregulation. Now these are important layers, but we have this robust misrepresentation of transtemperal identity. And I have always firmly said, you know this probably, that none of your listeners ever was or had a self and that we can explain everything we want to scientifically explain about self consciousness in a much more parsimonious way with much simpler assumptions, much simpler structural assumptions. So for me, the question is, in a system that very obviously has no immortal soul or no self, we don't find anything like that in the brain. How does this robust sense of selfhood emerge? Because that is really counterintuitive, right? Imagine people would try to believe that there is no such thing as a self. You cannot believe this, even if you want to believe this, nobody can believe it. Let me stop you there because I not only believe it, I experience it. I don't know if you have any significant experience with meditation or psychedelics or have you gone down that path to see if you could confirm any of the Buddha's claim here? Oh, I thought you knew that. Well, I do. I just don't know how far it's gone. Well, I'm a regular practitioner for almost 41 years. I've done many retreats. So on the 11th of September, I'll be a regular meditator for 41 years. I've been in many ashrams, monasteries in Asia, done long retreats. What practice have you done principally on retreat? Well, basically just classic straight with Pasa Na Samatha. So the whole classical thing, you can imagine that if one is into this for four decades, one has phases and tries out things and experiments too. But it's just the classical thing here. And I've gone to many Buddhist silent retreats for us. Yeah, yeah, great. So then when you say that no one can believe or imagine that the self is an illusion or that the self doesn't exist or that it's a hallucination to use your other term, what do you mean? Because clearly people have an experience, people claim to have an experience of losing their sense of self, losing the sense that there's a thinker in addition to thoughts or that there's a seer behind their eyes. The thinker, if that's the whole thing, if it's just the cognitive self model coming to rest, if you just mean this pure experience of effortless mindfulness, seeing out of emptiness, if that is enough for selflessness, then I know what you're talking about. But I think there's a much deeper problem behind it. So if somebody really reports about selflessness and states where there was no self and you're this conservative, stubborn, analytical, armchair philosopher who cannot imagine consciousness without self-consciousness, they will always say this is a performative self-contradiction. If you weren't there, why do you have an autobiographical memory of it? If you weren't there, this is not an episode of your life. So actually I don't have to believe your phenomenological reports about this because they contain a logical contradiction. That's one aspect. Another aspect is you may not imagine how many philosophers have such a lack of imagination that they always conflate self-consciousness and consciousness. There are so many people who think that this perspectival centeredness is a necessary aspect, but I can give a technical reason for this. If you try to mentally imagine a selfless experience, that is a mental action, the act of imagination, and it creates a sense of effort, a subtle sense of effort, and that's the selfiness. That's where the selfhood sits in, in the act of trying to imagine it. So you cannot imagine it. It's just like Thomas Nagel in his beautiful 1986 book, The View from Nowhere, thought he could imagine the universe from nowhere. But of course this wasn't the real thing. This was not a mystical experience. This was just an armchair thought experiment of a philosopher where he never lost the sense of self. So I mean, I'm absolutely certain that these experiences exist over the centuries and that they're also probably the most valuable states of consciousness human beings can experience. I also think that psychedelics play a major role in getting many people to take this dimension serious. Many of the meditation teachers in America have taken the standard route, which was to start with LSD in the 60s, then see this is not sustainable, go to Asia, become monks, and then return and become teachers here. That was the standard route for many to first experience ego dissolution with a pharmacological stimulus and then suddenly see the depth and the meaning that is there, but at the same time see this is a little risky and it's not sustainable and then go about it in another way. Yeah. That was certainly my route. I did it later, but I basically recapitulated the 60s curriculum for myself in the 80s. Yes. We both have... You are, I think, not so much aware of the commonalities, but we've had rough times on Pokhara Lake, but both of us. Really? I wasn't aware of that. I hope yours weren't as rough as mine. For people who want the details of mine, they can see my book Waking Up. You're putting me in a difficult situation because you're asking me to admit to illegal activities in the public here. It's just us, Thomas. I'll just put it like that. Either you're a consciousness researcher or you are not. Of course, there are many people who are just academic entrepreneurs in consciousness research, but I think anybody who has a serious and a deep interest in these issues, they will not talk. They will just try out everything, classical hallucinogens as well as serious sustained meditation practice. That's how you tell if somebody has a serious interest in the growth of knowledge and not only an interest in an academic career. That's also a part of the problem with a lot of the academic research, but that's another podcast. Thomas, I want to backtrack to something you said before. You made a distinction between the cognitive self and other things you might mean by self. When I'm talking about the dissolution of the sense of self that comes with meditation or can come with meditation, you said that if that's just the self you mean, well then of course you can experience selflessness, but it runs quite a bit deeper than that. What do you mean? How are you demarcating the cognitive self from other forms? Also, I have this theory, it's called the self model theory of subjectivity. If you'd like to continue listening to this conversation, you'll need to subscribe at SamHarris.org. Once you do, you'll get access to all full length episodes of the Making Sense Podcast along with other subscriber only content, including bonus episodes, NMAs and the conversations I've been having on the Waking Up app. The Making Sense Podcast is ad free and relies entirely on listener support. And you can subscribe now at SamHarris.org."}, "podcast_summary": "In this podcast episode, Sam Harris interviews philosopher Thomas Metzinger. They discuss various topics, including intuition in science, the ethics of building conscious AI, the nature of the self, and the limitations of secular humanism. Metzinger emphasizes the need for a theory of consciousness and the challenges of understanding the emergence of selfhood. He also touches on the role of meditation and psychedelics in exploring the nature of consciousness. While they debate the concept of the self and its illusory nature, they agree that consciousness is a complex and multifaceted phenomenon that is still being explored by the scientific community. Overall, the conversation delves into deep philosophical questions and highlights the importance of interdisciplinary collaboration in understanding consciousness.", "podcast_guest": "The podcast guest is Thomas Metzinger, who is a(n) Philosopher of Mind. The subject of this episode is Consciousness and the Self.", "podcast_highlights": "Highlights from the podcast episode with Thomas Metzinger:\n\n- Consciousness is not one problem, but a whole bundle of problems, some more conceptual and some more empirical.\n- The hard problem of consciousness, as framed by David Chalmers, is considered outdated by the consciousness community.\n- The mystery of consciousness is not that it is difficult to conceive how it emerges, but rather that any explanation may seem like a brute fact, not satisfying our intuitions.\n- The emergence of consciousness in non-biological machines may be difficult to grasp due to the presence of alien forms of conscious experience or selfhood, which may go unrecognized.\n- The self is not an illusion in the sense of being a sensory misrepresentation, but rather a robust misrepresentation of transtemporal identity.\n- The sense of selfhood is grounded in introspective self models, including inner sensations in the body, emotions, and bioregulation.\n- The experience of selflessness, as reported by meditation practitioners, can contain a logical contradiction and cannot be imagined conceptually.\n- Psychedelics play a role in getting many individuals to take selflessness and consciousness seriously, leading some to pursue sustained meditation practice."}